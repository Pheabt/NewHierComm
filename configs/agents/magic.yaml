

# --- RL hyperparameters ---


# --- Agent parameters ---
#agent: "rnn" # Default rnn agent
#hidden_dim: 64 # Size of hidden state for default rnn agent
#obs_agent_id: True # Include the agent's one_hot id in the observation
#obs_last_action: True # Include the agent's last action (one_hot) in the observation

# --- Experiment running params ---
#repeat_id: 1
#label: "default_label"
#hypergroup: null
# ---CommNet specific args---




mean_ratio: 0 #how much coooperative to do? 1.0 means fully cooperative


# ---magic specific args---
magic: True
directed: True #whether the communication graph is directed
self_loop_type1: 1 #self loop type in the first gat layer (0: no self loop, 1: with self loop, 2: decided by hard attn mechanism)
self_loop_type2: 1 #self loop type in the second gat layer (0: no self loop, 1: with self loop, 2: decided by hard attn mechanism)
gat_num_heads: 4 #number of heads in gat layers except the last one
gat_num_heads_out: 1 #number of heads in output gat layer
gat_hid_size: 32 #hidden size of one head in gat
ge_num_heads: 4 #number of heads in the gat encoder
first_gat_normalize: False #whether normalize the coefficients in the first gat layer of the message processor
second_gat_normalize: False #whether normilize the coefficients in the second gat layer of the message proccessor
gat_encoder_normalize: False #whether normilize the coefficients in the gat encoder (they have been normalized if the input graph is complete
use_gat_encoder: False #whether use the gat encoder before learning the first graph
gat_encoder_out_size: 64 #hidden size of output of the gat encoder
first_graph_complete: True #whether the first communication graph is set to a complete graph
second_graph_complete: True #whether the second communication graph is set to a complete graph
learn_second_graph: False #whether learn a new communication graph at the second round of communication
message_encoder: False #whether use the message encoder
message_decoder: True #whether use the message decoder
hid_size: 64
comm_init: 'uniform' #how to initialise comm weights [uniform|zeros]
comm_mode: 'avg' #Type of mode for communication tensor calculation [avg|sum]
comm_passes: 1 #Number of comm passes per step over the model
comm_mask_zero: False #Whether communication should be there

rnn_type: 'MLP' #type of rnn to use. [LSTM|MLP]
detach_gap: 10 #detach hidden state and cell state for rnns at this interval.' + ' Default 10000 (very high)

hard_attn: False #Whether to use hard attention: action - talk|silent
comm_action_one: False #Whether to always talk, sanity check for hard attention.
advantages_per_action: False #Whether to multipy log porb for each chosen action with advantages
share_weights: False #Share weights for hops








name: "magic"
