



# --- RL hyperparameters ---



# --- Agent parameters ---
#agent: "rnn" # Default rnn agent
#hidden_dim: 64 # Size of hidden state for default rnn agent
#obs_agent_id: True # Include the agent's one_hot id in the observation
#obs_last_action: True # Include the agent's last action (one_hot) in the observation

# --- Experiment running params ---
#repeat_id: 1
#label: "default_label"
#hypergroup: null
# ---CommNet specific args---
commnet: True #enable commnet model
tarcomm: True #enable tarmac model (with commnet or ic3net)
comm_mode: 'avg' #Type of mode for communication tensor calculation [avg|sum]
comm_passes: 1 #Number of comm passes per step over the model
comm_mask_zero: False #Whether communication should be there
mean_ratio: 1.0 #how much coooperative to do? 1.0 means fully cooperative
rnn_type: 'LSTM' #type of rnn to use. [LSTM|MLP]
detach_gap: 10 #detach hidden state and cell state for rnns at this interval.' + ' Default 10000 (very high)
comm_init: 'uniform' #how to initialise comm weights [uniform|zeros]
hard_attn: False #Whether to use hard attention: action - talk|silent
comm_action_one: False #Whether to always talk, sanity check for hard attention.
advantages_per_action: False #Whether to multipy log porb for each chosen action with advantages
share_weights: False #Share weights for hops
hid_size: 64
recurrent: False  #make the model recurrent in time


name: "tarmac"