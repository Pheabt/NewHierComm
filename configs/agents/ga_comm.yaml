

num_epochs: 100 #number of training epochs
epoch_size: 10 #number of update iterations in an epoch
use_cuda: True # Use gpu by default unless it isn't available
nprocesses: 16 #How many processes to run
max_steps: 20 #force to end the game after this many steps
nactions: 1 #the number of agent actions (0 for continuous). Use N:M:K for multiple actions
action_scale: 1.0 #scale action output from model

# --- Logging options ---
use_tensorboard: False # Log results to tensorboard
use_wandb: True # Log results to wandb
save: False # Save the models to disk
save_every: 50000 # save the model after every n_th epoch
#checkpoint_path: "" # Load a checkpoint from this path
#evaluate: False # Evaluate model for test_nepisode episodes and quit (no training)
#load_step: 0 # Load model trained on this many timesteps (0 if choose max possible)
#save_replay: False # Saving the replay of the model loaded from checkpoint_path
#local_results_path: "results" # Path for local results

# --- RL hyperparameters ---
gamma: 1.0 #discount factor
tau: 1.0
batch_size: 500 # number of steps before each update (per thread)
hid_size: 64 #hidden layer size
qk_hid_size: 16 #key and query size for soft attention
value_hid_size: 32 #value size for soft attention
lrate: 0.001 # Learning rate for agents
entr: 0 #entropy regularization coeff
value_coeff: 0.01 #coeff for value loss term
optim_alpha: 0.99 # RMSProp alpha
optim_eps: 0.00001 # RMSProp epsilon
grad_norm_clip: 10 # Reduce magnitude of gradients above this L2 norm
add_value_last_step: True
recurrent: False #make the model recurrent in time

# --- Agent parameters ---
#agent: "rnn" # Default rnn agent
#hidden_dim: 64 # Size of hidden state for default rnn agent
#obs_agent_id: True # Include the agent's one_hot id in the observation
#obs_last_action: True # Include the agent's last action (one_hot) in the observation

# --- Experiment running params ---
#repeat_id: 1
#label: "default_label"
#hypergroup: null
# ---CommNet specific args---
commnet: True #enable commnet model
ic3net: False #enable ic3net model
tarcomm: False #enable tarmac model (with commnet or ic3net)
gacomm :True #enable gacomm model
nagents: 1 #Number of agents (used in multiagent)
comm_mode: 'avg' #Type of mode for communication tensor calculation [avg|sum]
comm_passes: 1 #Number of comm passes per step over the model
comm_mask_zero: False #Whether communication should be there
mean_ratio: 0 #how much coooperative to do? 1.0 means fully cooperative
rnn_type: 'MLP' #type of rnn to use. [LSTM|MLP]
detach_gap: 10000 #detach hidden state and cell state for rnns at this interval.' + ' Default 10000 (very high)
comm_init: 'uniform' #how to initialise comm weights [uniform|zeros]
hard_attn: False #Whether to use hard attention: action - talk|silent
comm_action_one: False #Whether to always talk, sanity check for hard attention. if args.env_name == "traffic_junction": True
advantages_per_action: False #Whether to multipy log porb for each chosen action with advantages
share_weights: False #Share weights for hops

name: "gacomm"